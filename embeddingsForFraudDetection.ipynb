{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "5a67681454d667c9c44b86359034d6452f23eaaf"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "451a430089e455c5f2538b6dc8479c527e3b822c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   step     type   amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
      "0     1  PAYMENT  9839.64  C1231006815       170136.0       160296.36   \n",
      "\n",
      "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
      "0  M1979787155             0.0             0.0        0               0  \n",
      "(6362620, 11)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('PS_20174392719_1491204439457_log.csv')\n",
    "print (df.head(1))\n",
    "print (df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "9e51fbcf5813377ffea3710b11499b35a56039a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8213, 11)\n"
     ]
    }
   ],
   "source": [
    "uniqueIds = df['nameOrig'].unique().tolist()\n",
    "dfFraud = df.loc[df['isFraud'] == 1]\n",
    "dfNotFraud = df.loc[df['isFraud'] == 0]\n",
    "print (dfFraud.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "dff270c4d5f6165833e95556df1f4dc246611b27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 11)\n"
     ]
    }
   ],
   "source": [
    "dfFinal = pd.concat([dfFraud.sample(n=50),dfNotFraud.sample(n=950)])\n",
    "print (dfFinal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "a9e9effd5a9fea0704199151c80b75f409be780d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#preprocess\n",
    "def norm(df,cols):\n",
    "    for col in cols:\n",
    "        df[col]=(df[col]-df[col].min())/(df[col].max()-df[col].min())\n",
    "    return df\n",
    "dfFinal = norm(dfFinal,['amount'])\n",
    "print (dfFinal['amount'].max())\n",
    "print (dfFinal['amount'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "75f5fb7b7778b177729182c7ddcb81b7b41d82d1"
   },
   "outputs": [],
   "source": [
    "listSent = []\n",
    "for row in dfFinal.iterrows():\n",
    "    index, data = row\n",
    "    sent = \"\"\n",
    "    for ind, val in enumerate(data.tolist()):\n",
    "        if ind in [1,3,6]:\n",
    "            sent = sent + val + \" \" \n",
    "        elif ind == 2:\n",
    "            if val >= 0.8:\n",
    "                sent = sent + \"HIGH \"\n",
    "            elif val >= 0.6:\n",
    "                sent = sent + \"MED \"\n",
    "            elif val >= 0.3:\n",
    "                sent = sent + \"LOW \"\n",
    "            else :\n",
    "                sent = sent + \"VLOW \"\n",
    "        elif ind == 9:\n",
    "            if val == 1:\n",
    "                sent = sent + \"Fraud \"\n",
    "            else:\n",
    "                sent = sent + \"NotFraud \"\n",
    "    listSent.append(sent.rstrip(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "013aefea4dc1dc3d8ba7a94a9176fd37a857b72e"
   },
   "outputs": [],
   "source": [
    "#corpus with - type, sourceid, amtrange, destid, isfraud\n",
    "corpus = listSent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "e13b11a4ef2d5a98f6c974d7a93d8b44cc980840"
   },
   "outputs": [],
   "source": [
    "#create a word list of corpus\n",
    "words = []\n",
    "for text in corpus:\n",
    "    for word in text.split(' '):\n",
    "        words.append(word)\n",
    "words = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "2f3a8129dcb1ae389ae46b742c7cb1a99eb6051e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         input        label\n",
      "0     TRANSFER          MED\n",
      "1     TRANSFER  C1185526711\n",
      "2     TRANSFER   C342454180\n",
      "3     TRANSFER        Fraud\n",
      "4          MED     TRANSFER\n",
      "5          MED  C1185526711\n",
      "6          MED   C342454180\n",
      "7          MED        Fraud\n",
      "8  C1185526711     TRANSFER\n",
      "9  C1185526711          MED\n",
      "(20000, 2)\n"
     ]
    }
   ],
   "source": [
    "#keeping window size as 4, generate all the neighbors.\n",
    "word2int = {}\n",
    "for i,word in enumerate(words):\n",
    "    word2int[word] = i\n",
    "sentences = []\n",
    "for sentence in corpus:\n",
    "    sentences.append(sentence.split())    \n",
    "WINDOW_SIZE = 4\n",
    "data = []\n",
    "count=0\n",
    "for sentence in sentences:\n",
    "    for idx, word in enumerate(sentence):\n",
    "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] : \n",
    "            if neighbor != word:\n",
    "                data.append([word, neighbor])\n",
    "    count+=1\n",
    "                \n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data, columns = ['input', 'label'])   \n",
    "print(df.head(10))                \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "89faa830b6473d7672db55f12426e9e9234529a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aishwarya/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#Draw graph using tensorflow\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "cc837e30f2e436cc16c2d9d62515149714206dc8"
   },
   "outputs": [],
   "source": [
    "ONE_HOT_DIM = len(words)\n",
    "# function to convert numbers to one hot vectors\n",
    "def to_one_hot_encoding(data_point_index):\n",
    "    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
    "    one_hot_encoding[data_point_index] = 1\n",
    "    return one_hot_encoding\n",
    "X = [] # input word\n",
    "Y = [] # target word\n",
    "for x, y in zip(df['input'], df['label']):\n",
    "    X.append(to_one_hot_encoding(word2int[ x ]))\n",
    "    Y.append(to_one_hot_encoding(word2int[ y ]))\n",
    "# convert them to numpy arrays\n",
    "X_train = np.asarray(X)\n",
    "Y_train = np.asarray(Y)\n",
    "# making placeholders for X_train and Y_train\n",
    "x = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "# word embedding will be 2 dimension for 2d visualization\n",
    "EMBEDDING_DIM = 2 \n",
    "# hidden layer: which represents word vector eventually\n",
    "W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))\n",
    "b1 = tf.Variable(tf.random_normal([1])) #bias\n",
    "hidden_layer = tf.add(tf.matmul(x,W1), b1)\n",
    "# output layer\n",
    "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, W2), b2))\n",
    "# loss function: cross entropy\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n",
    "# training operation\n",
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e3a1d7c670d426c44dcb3695b0e34cdc93228c59",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 loss is :  9.349032\n",
      "iteration 100 loss is :  8.006699\n",
      "iteration 200 loss is :  7.568957\n"
     ]
    }
   ],
   "source": [
    "#training phase\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) \n",
    "iteration = 5000\n",
    "for i in range(iteration):\n",
    "    # input is X_train which is one hot encoded word\n",
    "    # label is Y_train which is one hot encoded neighbor word\n",
    "    sess.run(train_op, feed_dict={x: X_train, y_label: Y_train})\n",
    "    if i % 100 == 0:\n",
    "        print('iteration '+str(i)+' loss is : ', sess.run(loss, feed_dict={x: X_train, y_label: Y_train}))\n",
    "# Now the hidden layer (W1 + b1) is actually the word look up table\n",
    "vectors = sess.run(W1 + b1)\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "899c302c04f3485048868b6135dafe83b2619ea2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#word vector in a table\n",
    "w2v_df = pd.DataFrame(vectors, columns = ['x1', 'x2'])\n",
    "w2v_df['word'] = words\n",
    "w2v_df = w2v_df[['word', 'x1', 'x2']]\n",
    "w2v_df\n",
    "# if w2v_df.any(w2v_df['word'])== 'fraud':\n",
    "#     print(w2v_df['word'])\n",
    "# print(w2v_df.loc[w2v_df['word'] == 'Fraud'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#wordvector in 2d chart\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n",
    "#     ax.annotate(word, (x1,x2 ))    \n",
    "    if word == \"Fraud\":\n",
    "        ax.plot(x1,x2,\"ro\")\n",
    "    elif word in ['HIGH','MED','LOW','VLOW']:\n",
    "        ax.plot(x1,x2,\"go\")\n",
    "    else:\n",
    "        ax.plot(x1,x2,\"b.\")\n",
    "PADDING = 1.0\n",
    "x_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n",
    "y_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n",
    "x_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n",
    "y_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n",
    "plt.xlim(x_axis_min,x_axis_max)\n",
    "plt.ylim(y_axis_min,y_axis_max)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "X = w2v_df.loc[w2v_df['word'] == 'Fraud']\n",
    "#print(w2v_df)\n",
    "df = X.loc[:, ('x1', 'x2')]\n",
    "k = df.values.tolist()\n",
    "#print(df)\n",
    "list = []\n",
    "l = []\n",
    "# for row in range(len(w2v_df)):\n",
    "#     list.append([w2v_df['x1'][1],w2v_df['x2'][2]])\n",
    "# euclidean_distances(list, k)\n",
    "#print([w2v_df['x1'][1],w2v_df['x2'][2]])\n",
    "from scipy.spatial import distance\n",
    "for row in range(len(w2v_df)):\n",
    "    #print(distance.euclidean([w2v_df['x1'][row],w2v_df['x2'][row]],k))\n",
    "    list.append([distance.euclidean([w2v_df['x1'][row],w2v_df['x2'][row]],k),w2v_df['word'][row]])\n",
    "#print(l)\n",
    "list = sorted(list)\n",
    "print(list)\n",
    "a = [1, 2]\n",
    "b = [4, 5]\n",
    "dst = distance.euclidean(a, b)\n",
    "#print(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "951163c2260d102378a7206eb07ac2d71bcc715c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "283e3a1e7c4431383ffda6201da3eb08628b59ae"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
